{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc221e30",
   "metadata": {
    "papermill": {
     "duration": 0.015123,
     "end_time": "2021-03-24T11:24:18.422928",
     "exception": false,
     "start_time": "2021-03-24T11:24:18.407805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook contains an example for teaching.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8342cb7",
   "metadata": {
    "papermill": {
     "duration": 0.013777,
     "end_time": "2021-03-24T11:24:18.450894",
     "exception": false,
     "start_time": "2021-03-24T11:24:18.437117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Automatic Machine Learning with H2O AutoML using Wage Data from 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbd05b7",
   "metadata": {
    "papermill": {
     "duration": 0.014076,
     "end_time": "2021-03-24T11:24:18.478815",
     "exception": false,
     "start_time": "2021-03-24T11:24:18.464739",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We illustrate how to predict an outcome variable Y in a high-dimensional setting, using the AutoML package *H2O* that covers the complete pipeline from the raw dataset to the deployable machine learning model. In last few years, AutoML or automated machine learning has become widely popular among data science community. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5333433f",
   "metadata": {
    "papermill": {
     "duration": 0.013915,
     "end_time": "2021-03-24T11:24:18.508556",
     "exception": false,
     "start_time": "2021-03-24T11:24:18.494641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can use AutoML as a benchmark and compare it to the methods that we used in the previous notebook where we applied one machine learning method after the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd30c6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "from sklearn import preprocessing\n",
    "import patsy\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d7d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the H2O package\n",
    "import h2o\n",
    "\n",
    "# start h2o cluster\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf49964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "rdata_read = pyreadr.read_r(\"../data/wage2015_subsample_inference.Rdata\")\n",
    "data = rdata_read[ 'data' ]\n",
    "n = data.shape[0]\n",
    "\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305bb8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages for splitting data\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Set Seed\n",
    "# to make the results replicable (generating random numbers)\n",
    "np.random.seed(0)\n",
    "random = np.random.randint(0, data.shape[0], size=math.floor(data.shape[0]))\n",
    "data[\"random\"] = random\n",
    "random    # the array does not change \n",
    "data_2 = data.sort_values(by=['random'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing sample \n",
    "train = data_2[ : math.floor(n*3/4)]    # training sample\n",
    "test =  data_2[ math.floor(n*3/4) : ]   # testing sample\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed9f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start h2o cluster\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb269c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data as h2o type\n",
    "train_h = h2o.H2OFrame(train)\n",
    "test_h = h2o.H2OFrame(test)\n",
    "\n",
    "# have a look at the data\n",
    "train_h.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0bfa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the variables\n",
    "y = 'lwage'\n",
    "\n",
    "data_columns = list(data)\n",
    "no_relev_col = ['wage','occ2', 'ind2', 'random', 'lwage']\n",
    "\n",
    "# This gives us: new_list = ['carrot' , 'lemon']\n",
    "x = [col for col in data_columns if col not in no_relev_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c48dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run AutoML for 10 base models and a maximal runtime of 100 seconds\n",
    "# Run AutoML for 30 seconds\n",
    "aml = H2OAutoML(max_runtime_secs = 100, max_models = 10, seed = 1)\n",
    "aml.train(x = x, y = y, training_frame = train_h, leaderboard_frame = test_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88df97d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "print(lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d295cdc1",
   "metadata": {},
   "source": [
    "We see that two Stacked Ensembles are at the top of the leaderboard. Stacked Ensembles often outperform a single model. The out-of-sample (test) MSE of the leading model is given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f6aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "aml.leaderboard['mse'][0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9c7ec9",
   "metadata": {},
   "source": [
    "The in-sample performance can be evaluated by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e47ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "aml.leader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0b36af",
   "metadata": {
    "papermill": {
     "duration": 0.027663,
     "end_time": "2021-03-24T11:25:13.491063",
     "exception": false,
     "start_time": "2021-03-24T11:25:13.463400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is in line with our previous results. To understand how the ensemble works, let's take a peek inside the Stacked Ensemble \"All Models\" model.  The \"All Models\" ensemble is an ensemble of all of the individual models in the AutoML run.  This is often the top performing model on the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95549783",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = h2o.as_list(aml.leaderboard['model_id'][0], use_pandas=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2236931",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ids[model_ids['model_id'].str.contains(\"StackedEnsemble_AllModels\")].values.tolist()\n",
    "model_id = model[0][0]\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b33c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "se = h2o.get_model('StackedEnsemble_AllModels_AutoML_20210420_101446')\n",
    "se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439e8999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Stacked Ensemble metalearner model\n",
    "metalearner = se.metalearner()\n",
    "metalearner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06402906",
   "metadata": {},
   "source": [
    "Examine the variable importance of the metalearner (combiner) algorithm in the ensemble. This shows us how much each base learner is contributing to the ensemble. The AutoML Stacked Ensembles use the default metalearner algorithm (GLM with non-negative weights), so the variable importance of the metalearner is actually the standardized coefficient magnitudes of the GLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7425b332",
   "metadata": {},
   "source": [
    "The table above gives us the variable importance of the metalearner in the ensemble. The AutoML Stacked Ensembles use the default metalearner algorithm (GLM with non-negative weights), so the variable importance of the metalearner is actually the standardized coefficient magnitudes of the GLM. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d86b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "metalearner.coef_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4160a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "metalearner.std_coef_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08c1586",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.get_model(model_id).metalearner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f423ad",
   "metadata": {
    "papermill": {
     "duration": 0.030956,
     "end_time": "2021-03-24T11:25:14.345344",
     "exception": false,
     "start_time": "2021-03-24T11:25:14.314388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generating Predictions Using Leader Model\n",
    "\n",
    "We can also generate predictions on a test sample using the leader model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dd2625",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = aml.predict(test_h)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb85276",
   "metadata": {},
   "source": [
    "This allows us to estimate the out-of-sample (test) MSE and the standard error as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38d7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2 = pred.as_data_frame()\n",
    "pred_aml = pred_2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5cb41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = test_h['lwage'].as_data_frame().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b070b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_basic = (Y_test-pred_aml)**2\n",
    "\n",
    "MSE_aml_basic = sm.OLS( resid_basic , np.ones( resid_basic.shape[0] ) ).fit().summary2().tables[1].iloc[0, 0:2]\n",
    "MSE_aml_basic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6725164f",
   "metadata": {},
   "source": [
    "We observe both a lower MSE and a lower standard error compared to our previous results (see [here](https://www.kaggle.com/janniskueck/pm3-notebook-newdata))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03b4c5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### By using model_performance()\n",
    "If needed, the standard model_performance() method can be applied to the AutoML leader model and a test set to generate an H2O model performance object.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaedabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = aml.leader.model_performance(test_h)\n",
    "perf"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
