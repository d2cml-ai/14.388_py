{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "806aa591-1308-4bc1-8581-52d14125f2bb",
   "metadata": {},
   "source": [
    "# DML inference using NN for gun ownership"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087316b5",
   "metadata": {
    "papermill": {
     "duration": 0.005558,
     "end_time": "2021-02-04T12:17:27.309488",
     "exception": false,
     "start_time": "2021-02-04T12:17:27.303930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The Effect of Gun Ownership on Gun-Homicide Rates using DML for neural nets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da09851d",
   "metadata": {
    "papermill": {
     "duration": 0.005661,
     "end_time": "2021-02-04T12:17:27.320615",
     "exception": false,
     "start_time": "2021-02-04T12:17:27.314954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this lab, we estimate the effect of gun ownership on the homicide rate by a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6089ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "from sklearn import preprocessing\n",
    "import patsy\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import hdmpy\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6897820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV, ElasticNetCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "import itertools\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "from itertools import compress\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb84921d-7078-421c-9706-31eba4f6df22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"https://raw.githubusercontent.com/d2cml-ai/14.388_py/main/data/gun_clean.csv\")\n",
    "data1.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9ffdfa",
   "metadata": {
    "papermill": {
     "duration": 0.017216,
     "end_time": "2021-02-13T17:30:14.432656",
     "exception": false,
     "start_time": "2021-02-13T17:30:14.415440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0757f7b",
   "metadata": {
    "papermill": {
     "duration": 0.017212,
     "end_time": "2021-02-13T17:30:14.467075",
     "exception": false,
     "start_time": "2021-02-13T17:30:14.449863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To account for heterogeneity across counties and time trends in  all variables, we remove from them county-specific and time-specific effects in the following preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "633cd7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f7015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################  Find Variable Names from Dataset ########################\n",
    "\n",
    "def varlist( df = None, type_dataframe = [ 'numeric' , 'categorical' , 'string' ],  pattern = \"\", exclude = None ):\n",
    "    varrs = []\n",
    "    \n",
    "    if ('numeric' in type_dataframe):\n",
    "        varrs = varrs + df.columns[ df.apply( is_numeric_dtype , axis = 0 ).to_list() ].tolist()\n",
    "    \n",
    "    if ('categorical' in type_dataframe):\n",
    "        varrs = varrs + df.columns[ df.apply( is_categorical_dtype , axis = 0 ).to_list() ].tolist()\n",
    "    \n",
    "    if ('string' in type_dataframe):\n",
    "        varrs = varrs + df.columns[ df.apply( is_string_dtype , axis = 0 ).to_list() ].tolist()\n",
    "    \n",
    "    grepl_result = np.array( [ re.search( pattern , variable ) is not None for variable in df.columns.to_list() ] )\n",
    "    \n",
    "    if exclude is None:\n",
    "        result = list(compress( varrs, grepl_result ) )\n",
    "    \n",
    "    else:\n",
    "        varrs_excluded = np.array( [var in exclude for var in varrs ] )\n",
    "        and_filter = np.logical_and( ~varrs_excluded ,  grepl_result )\n",
    "        result = list(compress( varrs, and_filter ) )\n",
    "    \n",
    "    return result   \n",
    "\n",
    "################################# Create Variables ###############################\n",
    "\n",
    "\n",
    "# Dummy Variables for Year and County Fixed Effects\n",
    "r = re.compile(\"X_Jfips\")\n",
    "fixed = list( filter( r.match, data1.columns.to_list() ) )\n",
    "year = varlist(data1, pattern=\"X_Tyear\")\n",
    "\n",
    "census = []\n",
    "census_var = [\"^AGE\", \"^BN\", \"^BP\", \"^BZ\", \"^ED\", \"^EL\",\"^HI\", \"^HS\", \"^INC\", \"^LF\", \"^LN\", \"^PI\", \"^PO\", \"^PP\", \"^PV\", \"^SPR\", \"^VS\"]\n",
    "\n",
    "for variable in census_var:\n",
    "    r = re.compile( variable )\n",
    "    census = census + list( filter( r.match, data1.columns.to_list() ) )\n",
    "\n",
    "    \n",
    "################################ Variables ##################################\n",
    "# Treatment Variable\n",
    "d = \"logfssl\"\n",
    "\n",
    "# Outcome Variable\n",
    "y = \"logghomr\"\n",
    "\n",
    "# Other Control Variables\n",
    "X1 = [\"logrobr\", \"logburg\", \"burg_missing\", \"robrate_missing\"]\n",
    "X2 = [\"newblack\", \"newfhh\", \"newmove\", \"newdens\", \"newmal\"]\n",
    "\n",
    "#################################  Partial out Fixed Effects ########################\n",
    "\n",
    "rdata = data1[['CountyCode']]\n",
    "\n",
    "# Variables to be Partialled-out\n",
    "varlist2 = [y] + [d] + X1 + X2 + census\n",
    "\n",
    "# Partial out Variables in varlist from year and county fixed effect\n",
    "for var_name in varlist2:\n",
    "    form = var_name + \" ~ \" + \"+\" + \" + \".join( year ) + \"+\" + \" + \".join( fixed )\n",
    "    rdata[f'{var_name}'] = smf.ols( formula = form , data = data1 ).fit().resid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c981806",
   "metadata": {
    "papermill": {
     "duration": 0.006178,
     "end_time": "2021-02-04T12:17:53.609824",
     "exception": false,
     "start_time": "2021-02-04T12:17:53.603646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DML for neural nets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f799e",
   "metadata": {
    "papermill": {
     "duration": 0.005978,
     "end_time": "2021-02-04T12:17:53.621881",
     "exception": false,
     "start_time": "2021-02-04T12:17:53.615903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following algorithm comsumes $Y$,$D$ and $Z$, and learns the residuals $\\tilde{Y}$ and $\\tilde{D}$ via a neural network, where the residuals are obtained by cross-validation (cross-fitting). Then, it prints the estimated coefficient Î² and the clustered standard error from the final OLS regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1cf0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "208be5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DML2_for_NN(z, d, y, nfold, clu, num_epochs, batch_size):\n",
    "    \n",
    "    kf = KFold(n_splits = nfold, shuffle=True) #Here we use kfold to generate kfolds\n",
    "    I = np.arange(0, len(d)) #To have a id vector from data\n",
    "    train_id, test_id =  [], [] #arrays to store kfold's ids\n",
    "\n",
    "    #generate and store kfold's id\n",
    "    for kfold_index in kf.split(I):\n",
    "        train_id.append(kfold_index[0])\n",
    "        test_id.append(kfold_index[1])\n",
    "\n",
    "    # loop to save results\n",
    "    for b in range(0,len(train_id)):\n",
    "        # Normalize the data\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        scaler.fit( z[train_id[b],] )\n",
    "        z[train_id[b],] = scaler.transform( z[train_id[b],] )\n",
    "\n",
    "        scaler.fit( z[test_id[b],] )\n",
    "        z[test_id[b],] = scaler.transform( z[test_id[b],] )\n",
    "        \n",
    "        # building the model\n",
    "        # define the keras model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(16, input_dim = z[train_id[b],].shape[1], activation = 'relu'))\n",
    "        model.add(Dense(16, activation = 'relu'))\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "        # compile the keras model\n",
    "        opt = keras.optimizers.RMSprop()\n",
    "        mse = tf.keras.losses.MeanSquaredError()\n",
    "        mae = tf.keras.metrics.MeanAbsoluteError(name=\"mean_absolute_error\", dtype=None)\n",
    "        model.compile(loss=mse, optimizer= opt , metrics=mae)\n",
    "\n",
    "        # Fit and predict dhat\n",
    "        model.fit(z[train_id[b],], d[train_id[b],], epochs=num_epochs, batch_size=batch_size, verbose = 0)\n",
    "        dhat = model.predict(z[test_id[b],])\n",
    "        \n",
    "        # Fit and predict yhat\n",
    "        model.fit(z[train_id[b],], y[train_id[b],], epochs=num_epochs, batch_size=batch_size, verbose = 0)\n",
    "        yhat = model.predict(z[test_id[b],])\n",
    "\n",
    "        # Create array to save errors \n",
    "        dtil = np.zeros( len(z) ).reshape( len(z) , 1 )\n",
    "        ytil = np.zeros( len(z) ).reshape( len(z) , 1 )\n",
    "\n",
    "        # save errors  \n",
    "        dtil[test_id[b]] =  d[test_id[b],] - dhat.reshape( -1 , 1 )\n",
    "        ytil[test_id[b]] = y[test_id[b],] - yhat.reshape( -1 , 1 )\n",
    "        print(b, \" \")\n",
    "    \n",
    "    # Create dataframe \n",
    "    data_2 = pd.DataFrame(np.concatenate( ( ytil, dtil,clu ), axis = 1), columns = ['ytil','dtil','CountyCode'])\n",
    "   \n",
    "    # OLS clustering at the County level\n",
    "    model = \"ytil ~ dtil\"\n",
    "    rfit = smf.ols(model , data=data_2).fit().get_robustcov_results(cov_type = \"cluster\", groups= data_2['CountyCode'])\n",
    "    \n",
    "    coef_est = rfit.summary2().tables[1]['Coef.']['dtil']\n",
    "    se = rfit.summary2().tables[1]['Std.Err.']['dtil']\n",
    "\n",
    "    print(\"Coefficient is {}, SE is equal to {}\".format(coef_est, se))\n",
    "    \n",
    "    return coef_est, se, dtil, ytil, rfit\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b54cf46-bab6-41e3-ab87-242b83a17f21",
   "metadata": {},
   "source": [
    "## Estimating the effect with DML for neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bb6fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create main variables\n",
    "Y = rdata['logghomr']\n",
    "D = rdata['logfssl']\n",
    "Z = rdata.drop(['logghomr', 'logfssl', 'CountyCode'], axis=1)\n",
    "CLU = rdata['CountyCode']\n",
    "\n",
    "# as matrix\n",
    "y = Y.to_numpy().reshape( len(Y) , 1 )\n",
    "d = D.to_numpy().reshape( len(Y) , 1 )\n",
    "z = Z.to_numpy()\n",
    "clu = CLU.to_numpy().reshape( len(Y) , 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f024eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 2ms/step\n",
      "61/61 [==============================] - 0s 2ms/step\n",
      "0  \n",
      "61/61 [==============================] - 0s 3ms/step\n",
      "61/61 [==============================] - 0s 2ms/step\n",
      "1  \n",
      "Coefficient is 0.15088735423105293, SE is equal to 0.08458123583830866\n"
     ]
    }
   ],
   "source": [
    "DML2_nn = DML2_for_NN(z, d, y, 2, clu, 100, 10)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
