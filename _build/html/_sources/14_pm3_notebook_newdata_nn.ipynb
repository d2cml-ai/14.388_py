{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010003,
     "end_time": "2021-03-28T13:27:45.376868",
     "exception": false,
     "start_time": "2021-03-28T13:27:45.366865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "This notebook contains an example for teaching.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "051d70d956493feee0c6d64651c6a088724dca2a",
    "papermill": {
     "duration": 0.008782,
     "end_time": "2021-03-28T13:27:45.395504",
     "exception": false,
     "start_time": "2021-03-28T13:27:45.386722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A Simple Case Study using Wage Data from 2015 - proceeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008735,
     "end_time": "2021-03-28T13:27:45.413302",
     "exception": false,
     "start_time": "2021-03-28T13:27:45.404567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So far we considered many machine learning method, e.g Lasso and Random Forests, to build a predictive model. In this lab, we extend our toolbox by predicting wages by a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009256,
     "end_time": "2021-03-28T13:27:45.431663",
     "exception": false,
     "start_time": "2021-03-28T13:27:45.422407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0088,
     "end_time": "2021-03-28T13:27:45.449606",
     "exception": false,
     "start_time": "2021-03-28T13:27:45.440806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Again, we consider data from the U.S. March Supplement of the Current Population Survey (CPS) in 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This notebook contains an example for teaching.\n",
    "\n",
    "\n",
    "# A Simple Case Study using Wage Data from 2015 - proceeding\n",
    "\n",
    "So far we considered many machine learning method, e.g Lasso and Random Forests, to build a predictive model. In this lab, we extend our toolbox by predicting wages by a neural network.\n",
    "\n",
    "## Data preparation\n",
    "\n",
    "Again, we consider data from the U.S. March Supplement of the Current Population Survey (CPS) in 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "from sklearn import preprocessing\n",
    "import patsy\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata_read = pyreadr.read_r(\"../data/wage2015_subsample_inference.Rdata\")\n",
    "data = rdata_read[ 'data' ]\n",
    "n = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2732, 2607, 1653, ..., 4184, 2349, 3462])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import relevant packages for splitting data\n",
    "import random\n",
    "import math\n",
    "# Set Seed\n",
    "# to make the results replicable (generating random numbers)\n",
    "np.random.seed(0)\n",
    "random = np.random.randint(0, data.shape[0], size=math.floor(data.shape[0]))\n",
    "data[\"random\"] = random\n",
    "random    # the array does not change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>lwage</th>\n",
       "      <th>sex</th>\n",
       "      <th>shs</th>\n",
       "      <th>hsg</th>\n",
       "      <th>scl</th>\n",
       "      <th>clg</th>\n",
       "      <th>ad</th>\n",
       "      <th>mw</th>\n",
       "      <th>so</th>\n",
       "      <th>...</th>\n",
       "      <th>ne</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "      <th>exp4</th>\n",
       "      <th>occ</th>\n",
       "      <th>occ2</th>\n",
       "      <th>ind</th>\n",
       "      <th>ind2</th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rownames</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>26.442308</td>\n",
       "      <td>3.274965</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.4100</td>\n",
       "      <td>24.389000</td>\n",
       "      <td>70.728100</td>\n",
       "      <td>340</td>\n",
       "      <td>1</td>\n",
       "      <td>8660</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>19.230769</td>\n",
       "      <td>2.956512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>11.2225</td>\n",
       "      <td>37.595375</td>\n",
       "      <td>125.944506</td>\n",
       "      <td>9620</td>\n",
       "      <td>22</td>\n",
       "      <td>1870</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13501</th>\n",
       "      <td>48.076923</td>\n",
       "      <td>3.872802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>3060</td>\n",
       "      <td>10</td>\n",
       "      <td>8190</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15588</th>\n",
       "      <td>12.019231</td>\n",
       "      <td>2.486508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.4100</td>\n",
       "      <td>24.389000</td>\n",
       "      <td>70.728100</td>\n",
       "      <td>6440</td>\n",
       "      <td>19</td>\n",
       "      <td>770</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16049</th>\n",
       "      <td>39.903846</td>\n",
       "      <td>3.686473</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.4400</td>\n",
       "      <td>1.728000</td>\n",
       "      <td>2.073600</td>\n",
       "      <td>1820</td>\n",
       "      <td>5</td>\n",
       "      <td>7860</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27533</th>\n",
       "      <td>21.634615</td>\n",
       "      <td>3.074295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1860</td>\n",
       "      <td>5</td>\n",
       "      <td>7870</td>\n",
       "      <td>17</td>\n",
       "      <td>5146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7218</th>\n",
       "      <td>13.461538</td>\n",
       "      <td>2.599837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.8400</td>\n",
       "      <td>21.952000</td>\n",
       "      <td>61.465600</td>\n",
       "      <td>4220</td>\n",
       "      <td>14</td>\n",
       "      <td>1170</td>\n",
       "      <td>5</td>\n",
       "      <td>5146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7204</th>\n",
       "      <td>27.403846</td>\n",
       "      <td>3.310683</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>1760</td>\n",
       "      <td>5</td>\n",
       "      <td>7460</td>\n",
       "      <td>14</td>\n",
       "      <td>5146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>16.695804</td>\n",
       "      <td>2.815157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.8400</td>\n",
       "      <td>21.952000</td>\n",
       "      <td>61.465600</td>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>9570</td>\n",
       "      <td>22</td>\n",
       "      <td>5149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10451</th>\n",
       "      <td>45.528846</td>\n",
       "      <td>3.818346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.2100</td>\n",
       "      <td>1.331000</td>\n",
       "      <td>1.464100</td>\n",
       "      <td>1107</td>\n",
       "      <td>3</td>\n",
       "      <td>6990</td>\n",
       "      <td>12</td>\n",
       "      <td>5149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5150 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               wage     lwage  sex  shs  hsg  scl  clg   ad   mw   so  ...  \\\n",
       "rownames                                                               ...   \n",
       "2223      26.442308  3.274965  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3467      19.230769  2.956512  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   \n",
       "13501     48.076923  3.872802  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  ...   \n",
       "15588     12.019231  2.486508  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  ...   \n",
       "16049     39.903846  3.686473  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...   \n",
       "...             ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "27533     21.634615  3.074295  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...   \n",
       "7218      13.461538  2.599837  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  ...   \n",
       "7204      27.403846  3.310683  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  ...   \n",
       "1380      16.695804  2.815157  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   \n",
       "10451     45.528846  3.818346  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  ...   \n",
       "\n",
       "           ne  exp1     exp2       exp3        exp4   occ occ2   ind ind2  \\\n",
       "rownames                                                                    \n",
       "2223      1.0  29.0   8.4100  24.389000   70.728100   340    1  8660   20   \n",
       "3467      1.0  33.5  11.2225  37.595375  125.944506  9620   22  1870    5   \n",
       "13501     0.0   2.0   0.0400   0.008000    0.001600  3060   10  8190   18   \n",
       "15588     0.0  29.0   8.4100  24.389000   70.728100  6440   19   770    4   \n",
       "16049     0.0  12.0   1.4400   1.728000    2.073600  1820    5  7860   17   \n",
       "...       ...   ...      ...        ...         ...   ...  ...   ...  ...   \n",
       "27533     0.0  10.0   1.0000   1.000000    1.000000  1860    5  7870   17   \n",
       "7218      0.0  28.0   7.8400  21.952000   61.465600  4220   14  1170    5   \n",
       "7204      0.0   4.0   0.1600   0.064000    0.025600  1760    5  7460   14   \n",
       "1380      1.0  28.0   7.8400  21.952000   61.465600  2000    6  9570   22   \n",
       "10451     0.0  11.0   1.2100   1.331000    1.464100  1107    3  6990   12   \n",
       "\n",
       "         random  \n",
       "rownames         \n",
       "2223          0  \n",
       "3467          0  \n",
       "13501         0  \n",
       "15588         2  \n",
       "16049         2  \n",
       "...         ...  \n",
       "27533      5146  \n",
       "7218       5146  \n",
       "7204       5146  \n",
       "1380       5149  \n",
       "10451      5149  \n",
       "\n",
       "[5150 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2 = data.sort_values(by=['random'])\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3862, 21)\n",
      "(1288, 21)\n"
     ]
    }
   ],
   "source": [
    "# Create training and testing sample \n",
    "data_train = data_2[ : math.floor(n*3/4)]    # training sample\n",
    "data_test =  data_2[ math.floor(n*3/4) : ]   # testing sample\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>lwage</th>\n",
       "      <th>sex</th>\n",
       "      <th>shs</th>\n",
       "      <th>hsg</th>\n",
       "      <th>scl</th>\n",
       "      <th>clg</th>\n",
       "      <th>ad</th>\n",
       "      <th>mw</th>\n",
       "      <th>so</th>\n",
       "      <th>we</th>\n",
       "      <th>ne</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "      <th>exp4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rownames</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9210</th>\n",
       "      <td>29.807692</td>\n",
       "      <td>3.394766</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.84</td>\n",
       "      <td>10.648</td>\n",
       "      <td>23.4256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16484</th>\n",
       "      <td>43.269231</td>\n",
       "      <td>3.767442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>4.913</td>\n",
       "      <td>8.3521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16448</th>\n",
       "      <td>24.038462</td>\n",
       "      <td>3.179655</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.331</td>\n",
       "      <td>1.4641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27392</th>\n",
       "      <td>10.097115</td>\n",
       "      <td>2.312250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>27.000</td>\n",
       "      <td>81.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11596</th>\n",
       "      <td>8.653846</td>\n",
       "      <td>2.158004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27533</th>\n",
       "      <td>21.634615</td>\n",
       "      <td>3.074295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7218</th>\n",
       "      <td>13.461538</td>\n",
       "      <td>2.599837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.84</td>\n",
       "      <td>21.952</td>\n",
       "      <td>61.4656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7204</th>\n",
       "      <td>27.403846</td>\n",
       "      <td>3.310683</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.0256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>16.695804</td>\n",
       "      <td>2.815157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.84</td>\n",
       "      <td>21.952</td>\n",
       "      <td>61.4656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10451</th>\n",
       "      <td>45.528846</td>\n",
       "      <td>3.818346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.331</td>\n",
       "      <td>1.4641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1288 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               wage     lwage  sex  shs  hsg  scl  clg   ad   mw   so   we  \\\n",
       "rownames                                                                     \n",
       "9210      29.807692  3.394766  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "16484     43.269231  3.767442  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "16448     24.038462  3.179655  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "27392     10.097115  2.312250  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "11596      8.653846  2.158004  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "...             ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "27533     21.634615  3.074295  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0   \n",
       "7218      13.461538  2.599837  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "7204      27.403846  3.310683  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "1380      16.695804  2.815157  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "10451     45.528846  3.818346  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
       "\n",
       "           ne  exp1  exp2    exp3     exp4  \n",
       "rownames                                    \n",
       "9210      0.0  22.0  4.84  10.648  23.4256  \n",
       "16484     0.0  17.0  2.89   4.913   8.3521  \n",
       "16448     0.0  11.0  1.21   1.331   1.4641  \n",
       "27392     0.0  30.0  9.00  27.000  81.0000  \n",
       "11596     0.0   6.0  0.36   0.216   0.1296  \n",
       "...       ...   ...   ...     ...      ...  \n",
       "27533     0.0  10.0  1.00   1.000   1.0000  \n",
       "7218      0.0  28.0  7.84  21.952  61.4656  \n",
       "7204      0.0   4.0  0.16   0.064   0.0256  \n",
       "1380      1.0  28.0  7.84  21.952  61.4656  \n",
       "10451     0.0  11.0  1.21   1.331   1.4641  \n",
       "\n",
       "[1288 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = data_train.iloc[:, 0:16]\n",
    "data_test = data_test.iloc[:, 0:16] \n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler =  MinMaxScaler().fit(data_train)\n",
    "scaler =  MinMaxScaler().fit(data_test)\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(data_train)\n",
    "# scaler = preprocessing.StandardScaler().fit(data_test)\n",
    "\n",
    "data_train_scaled = scaler.transform(data_train)\n",
    "data_test_scaled = scaler.transform(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>lwage</th>\n",
       "      <th>sex</th>\n",
       "      <th>shs</th>\n",
       "      <th>hsg</th>\n",
       "      <th>scl</th>\n",
       "      <th>clg</th>\n",
       "      <th>ad</th>\n",
       "      <th>mw</th>\n",
       "      <th>so</th>\n",
       "      <th>we</th>\n",
       "      <th>ne</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "      <th>exp4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054875</td>\n",
       "      <td>0.447819</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082510</td>\n",
       "      <td>0.521313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.149277</td>\n",
       "      <td>0.057675</td>\n",
       "      <td>0.022284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043032</td>\n",
       "      <td>0.405398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014412</td>\n",
       "      <td>0.234342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.464876</td>\n",
       "      <td>0.316961</td>\n",
       "      <td>0.216110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011449</td>\n",
       "      <td>0.203924</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.018595</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>0.038097</td>\n",
       "      <td>0.384621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.051653</td>\n",
       "      <td>0.011739</td>\n",
       "      <td>0.002668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>0.021318</td>\n",
       "      <td>0.291056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.257701</td>\n",
       "      <td>0.163992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>0.049940</td>\n",
       "      <td>0.431238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>0.027958</td>\n",
       "      <td>0.333518</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.257701</td>\n",
       "      <td>0.163992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>0.087149</td>\n",
       "      <td>0.531351</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1288 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          wage     lwage  sex  shs  hsg  scl  clg   ad   mw   so   we   ne  \\\n",
       "0     0.054875  0.447819  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "1     0.082510  0.521313  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
       "2     0.043032  0.405398  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
       "3     0.014412  0.234342  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "4     0.011449  0.203924  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "...        ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1283  0.038097  0.384621  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "1284  0.021318  0.291056  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "1285  0.049940  0.431238  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0   \n",
       "1286  0.027958  0.333518  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "1287  0.087149  0.531351  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0   \n",
       "\n",
       "          exp1      exp2      exp3      exp4  \n",
       "0     0.500000  0.250000  0.125000  0.062500  \n",
       "1     0.386364  0.149277  0.057675  0.022284  \n",
       "2     0.250000  0.062500  0.015625  0.003906  \n",
       "3     0.681818  0.464876  0.316961  0.216110  \n",
       "4     0.136364  0.018595  0.002536  0.000346  \n",
       "...        ...       ...       ...       ...  \n",
       "1283  0.227273  0.051653  0.011739  0.002668  \n",
       "1284  0.636364  0.404959  0.257701  0.163992  \n",
       "1285  0.090909  0.008264  0.000751  0.000068  \n",
       "1286  0.636364  0.404959  0.257701  0.163992  \n",
       "1287  0.250000  0.062500  0.015625  0.003906  \n",
       "\n",
       "[1288 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_scaled = pd.DataFrame(data_train_scaled, columns = columns)\n",
    "data_test_scaled = pd.DataFrame(data_test_scaled, columns = columns)\n",
    "data_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we construct the inputs for our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_basic = \"lwage ~ sex + exp1 + shs + hsg+ scl + clg + mw + so + we\"\n",
    "Y_train, model_X_basic_train = patsy.dmatrices(formula_basic, data_train_scaled, return_type='dataframe')\n",
    "Y_test, model_X_basic_test = patsy.dmatrices(formula_basic, data_test_scaled, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to determine the structure of our network. We are using the R/python package *keras* to build a simple sequential neural network with three dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_X_basic_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim = model_X_basic_train.shape[1], activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "# model.add(Dense(5, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "opt = keras.optimizers.Adam(learning_rate=0.005)\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "mae = tf.keras.metrics.MeanAbsoluteError(name=\"mean_absolute_error\", dtype=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a look at the structure of our network in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                220       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 441\n",
      "Trainable params: 441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=mse, optimizer= opt , metrics=mae)\n",
    "model.summary(line_length=None, positions=None, print_fn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth to notice that we have in total $441$ trainable parameters.\n",
    "\n",
    "Now, let us train the network. Note that this takes some computation time. Thus, we are using gpu to speed up. The exact speed-up varies based on a number of factors including model architecture, batch-size, input pipeline complexity, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the keras model on the dataset\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check this [link](https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network), to understand batch_size argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "387/387 [==============================] - 2s 2ms/step - loss: 0.0138 - mean_absolute_error: 0.0891\n",
      "Epoch 2/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0113 - mean_absolute_error: 0.0812\n",
      "Epoch 3/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0111 - mean_absolute_error: 0.0806\n",
      "Epoch 4/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0110 - mean_absolute_error: 0.0804\n",
      "Epoch 5/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0109 - mean_absolute_error: 0.0796\n",
      "Epoch 6/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0107 - mean_absolute_error: 0.0791\n",
      "Epoch 7/150\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.0107 - mean_absolute_error: 0.0789\n",
      "Epoch 8/150\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.0107 - mean_absolute_error: 0.0787\n",
      "Epoch 9/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0106 - mean_absolute_error: 0.0783\n",
      "Epoch 10/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0106 - mean_absolute_error: 0.0785\n",
      "Epoch 11/150\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.0106 - mean_absolute_error: 0.0787\n",
      "Epoch 12/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0105 - mean_absolute_error: 0.0784\n",
      "Epoch 13/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0106 - mean_absolute_error: 0.0785\n",
      "Epoch 14/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0106 - mean_absolute_error: 0.0786\n",
      "Epoch 15/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0105 - mean_absolute_error: 0.0781\n",
      "Epoch 16/150\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.0106 - mean_absolute_error: 0.0788\n",
      "Epoch 17/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0105 - mean_absolute_error: 0.0783\n",
      "Epoch 18/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0105 - mean_absolute_error: 0.0784\n",
      "Epoch 19/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0105 - mean_absolute_error: 0.0782\n",
      "Epoch 20/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0105 - mean_absolute_error: 0.0784\n",
      "Epoch 21/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0104 - mean_absolute_error: 0.0782\n",
      "Epoch 22/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0106 - mean_absolute_error: 0.0784\n",
      "Epoch 23/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0105 - mean_absolute_error: 0.0782\n",
      "Epoch 24/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0104 - mean_absolute_error: 0.0785\n",
      "Epoch 25/150\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.0105 - mean_absolute_error: 0.0783\n",
      "Epoch 26/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0105 - mean_absolute_error: 0.0779\n",
      "Epoch 27/150\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.0104 - mean_absolute_error: 0.0781\n",
      "Epoch 28/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0105 - mean_absolute_error: 0.0781\n",
      "Epoch 29/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0104 - mean_absolute_error: 0.0776\n",
      "Epoch 30/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0105 - mean_absolute_error: 0.0782\n",
      "Epoch 31/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0104 - mean_absolute_error: 0.0777\n",
      "Epoch 32/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0776\n",
      "Epoch 33/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0776\n",
      "Epoch 34/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0772\n",
      "Epoch 35/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0104 - mean_absolute_error: 0.0779\n",
      "Epoch 36/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0104 - mean_absolute_error: 0.0779\n",
      "Epoch 37/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0104 - mean_absolute_error: 0.0778\n",
      "Epoch 38/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0104 - mean_absolute_error: 0.0777\n",
      "Epoch 39/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0772\n",
      "Epoch 40/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0775\n",
      "Epoch 41/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0772\n",
      "Epoch 42/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0774\n",
      "Epoch 43/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0775\n",
      "Epoch 44/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0776\n",
      "Epoch 45/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0774\n",
      "Epoch 46/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0775\n",
      "Epoch 47/150\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.0103 - mean_absolute_error: 0.0773\n",
      "Epoch 48/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0773\n",
      "Epoch 49/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0772\n",
      "Epoch 50/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0777\n",
      "Epoch 51/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0774\n",
      "Epoch 52/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 53/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0775\n",
      "Epoch 54/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0775\n",
      "Epoch 55/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0775\n",
      "Epoch 56/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0775\n",
      "Epoch 57/150\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.0103 - mean_absolute_error: 0.0775\n",
      "Epoch 58/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0774\n",
      "Epoch 59/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0774\n",
      "Epoch 60/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0773\n",
      "Epoch 61/150\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.0103 - mean_absolute_error: 0.0775\n",
      "Epoch 62/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0776\n",
      "Epoch 63/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0773\n",
      "Epoch 64/150\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.0103 - mean_absolute_error: 0.0777\n",
      "Epoch 65/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0776\n",
      "Epoch 66/150\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.0102 - mean_absolute_error: 0.0770\n",
      "Epoch 67/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0774\n",
      "Epoch 68/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0774\n",
      "Epoch 69/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0772\n",
      "Epoch 70/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0777\n",
      "Epoch 71/150\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.0103 - mean_absolute_error: 0.0774\n",
      "Epoch 72/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0774\n",
      "Epoch 73/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0772\n",
      "Epoch 74/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 75/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0770\n",
      "Epoch 76/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0774\n",
      "Epoch 77/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0772\n",
      "Epoch 78/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0772\n",
      "Epoch 79/150\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 80/150\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.0102 - mean_absolute_error: 0.0770\n",
      "Epoch 81/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0772\n",
      "Epoch 82/150\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.0102 - mean_absolute_error: 0.0772\n",
      "Epoch 83/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0773\n",
      "Epoch 84/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0777\n",
      "Epoch 85/150\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.0103 - mean_absolute_error: 0.0774\n",
      "Epoch 86/150\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.0102 - mean_absolute_error: 0.0774\n",
      "Epoch 87/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0773\n",
      "Epoch 88/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0773\n",
      "Epoch 89/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0776\n",
      "Epoch 90/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0770\n",
      "Epoch 91/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 92/150\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 93/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0777\n",
      "Epoch 94/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0770\n",
      "Epoch 95/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0773\n",
      "Epoch 96/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0772\n",
      "Epoch 97/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 98/150\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0772\n",
      "Epoch 99/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0773\n",
      "Epoch 100/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0772\n",
      "Epoch 101/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0772\n",
      "Epoch 102/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 103/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0104 - mean_absolute_error: 0.0778\n",
      "Epoch 104/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0772\n",
      "Epoch 105/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 106/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0774\n",
      "Epoch 107/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0773\n",
      "Epoch 108/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 109/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0769\n",
      "Epoch 110/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0774\n",
      "Epoch 111/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0770\n",
      "Epoch 112/150\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0770\n",
      "Epoch 113/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 114/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0773\n",
      "Epoch 115/150\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0773\n",
      "Epoch 116/150\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.0103 - mean_absolute_error: 0.0774\n",
      "Epoch 117/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0770\n",
      "Epoch 118/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0769\n",
      "Epoch 119/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0768\n",
      "Epoch 120/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0773\n",
      "Epoch 121/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0770\n",
      "Epoch 122/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0772\n",
      "Epoch 123/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0773\n",
      "Epoch 124/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0769\n",
      "Epoch 125/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0770\n",
      "Epoch 126/150\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0773\n",
      "Epoch 127/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0772\n",
      "Epoch 128/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 129/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0773\n",
      "Epoch 130/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 131/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0770\n",
      "Epoch 132/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0770\n",
      "Epoch 133/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 134/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 135/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0770\n",
      "Epoch 136/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0103 - mean_absolute_error: 0.0775\n",
      "Epoch 137/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0770\n",
      "Epoch 138/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0101 - mean_absolute_error: 0.0766\n",
      "Epoch 139/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0769\n",
      "Epoch 140/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0101 - mean_absolute_error: 0.0767\n",
      "Epoch 141/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0101 - mean_absolute_error: 0.0770\n",
      "Epoch 142/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0767\n",
      "Epoch 143/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0101 - mean_absolute_error: 0.0767\n",
      "Epoch 144/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0101 - mean_absolute_error: 0.0770\n",
      "Epoch 145/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0769\n",
      "Epoch 146/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0770\n",
      "Epoch 147/150\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 148/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 149/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0771\n",
      "Epoch 150/150\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27e13c62b50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(model_X_basic_train, Y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'mean_absolute_error']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01021327544003725, 0.0775848850607872]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(model_X_basic_test, Y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.31040493],\n",
       "       [0.42235863],\n",
       "       [0.39654243],\n",
       "       ...,\n",
       "       [0.3823735 ],\n",
       "       [0.40649807],\n",
       "       [0.38370064]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_nn = model.predict(model_X_basic_test)\n",
    "pred_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_basic = (Y_test-pred_nn)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coef.       0.010213\n",
       "Std.Err.    0.000552\n",
       "Name: const, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_nn_basic = sm.OLS( resid_basic , np.ones( resid_basic.shape[0] ) ).fit().summary2().tables[1].iloc[0, 0:2]\n",
    "MSE_nn_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 using NN is equal to = 0.1511966373372956\n"
     ]
    }
   ],
   "source": [
    "R2_nn_basic = 1 - ( MSE_nn_basic[0]/Y_test.var() )\n",
    "print( f\"The R^2 using NN is equal to = {R2_nn_basic[0]}\" ) # MSE NN (basic model) "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
